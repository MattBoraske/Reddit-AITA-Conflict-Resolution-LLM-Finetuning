{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit AITA Huggingface Dataset Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Input files from datafile_filtering:\n",
    "1. AITA submissions with at least 50 score\n",
    "2. Top level comments that had at least 10 score for the AITA submissions with at least 50 score\n",
    "\n",
    "1 Output file:\n",
    "1. CSV/ZST file where each row is an AITA submission with at least 50 score that has columns for the top 10 comments where each comment has at least 10 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install zstandard\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zstandard as zstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of AITA submissions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load submissions csv\n",
    "\n",
    "submissions_df = pd.read_csv('new_datasets/submissions_2019_to_2022_at_least_50_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter submissions df to include only relevant link_flair_text (decision) values\n",
    "# relevant AITA classes - a**hole, not the a-hole, no a-holes here, everyone sucks, not enough info\n",
    "\n",
    "submissions_df = submissions_df[submissions_df['link_flair_text'].isin(['Asshole', 'Not the A-hole', 'No A-holes here', 'Everyone Sucks', 'Not enough info'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns so that they better reflect their data\n",
    "\n",
    "submissions_df = submissions_df.rename(columns={'id': 'submission_id',\n",
    "                                      'link_flair_text': 'decision',\n",
    "                                      'score': 'submission_score',\n",
    "                                      'title': 'submission_title',\n",
    "                                      'selftext': 'submission_text',\n",
    "                                      'url': 'submission_url'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of AITA comments dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load comments csv\n",
    "\n",
    "comments_df = pd.read_csv('new_datasets/top_level_comments_2019_to_2022_at_least_10_comment_score_at_least_50_submission_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the t3_ from the link_id column\n",
    "\n",
    "comments_df['link_id'] = comments_df['link_id'].str.slice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns so that they better reflect their data\n",
    "\n",
    "comments_df = comments_df.rename(columns={'id': 'comment_id',\n",
    "                                      'score': 'comment_score',\n",
    "                                      'body': 'comment_text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging of AITA submission and comments dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the top 10 comments for each submission\n",
    "\n",
    "merged_df = submissions_df.merge(comments_df, left_on='submission_id', right_on='link_id') # merge submission and top comments dataframes\n",
    "merged_df = merged_df.drop('link_id', axis=1) # remove link_id column\n",
    "top_10_comments = merged_df.groupby('submission_id').apply(lambda x: x.nlargest(10, 'comment_score')['comment_text'].tolist()) # group by submission_id and get the top 10 comments for each submission\n",
    "top_10_comments_df = pd.DataFrame(top_10_comments.tolist(), index=top_10_comments.index).add_prefix('comment_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge submissions_df and top_10_comments_df on submission_id\n",
    "# Result is a dataframe with both submissions and their top 10 comments\n",
    "\n",
    "submissions_with_top_10_comments = submissions_df.merge(top_10_comments_df, on='submission_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with deleted/removed/null submission texts or top comments\n",
    "\n",
    "submissions_with_top_10_comments = submissions_with_top_10_comments[(submissions_with_top_10_comments['submission_text'] != '[deleted]') & \n",
    "                                                                    (submissions_with_top_10_comments['comment_0'] != '[deleted]') &\n",
    "                                                                    (submissions_with_top_10_comments['submission_text'] != '[removed]') &\n",
    "                                                                    (submissions_with_top_10_comments['comment_0'] != '[removed]') &\n",
    "                                                                    (submissions_with_top_10_comments['submission_text'].notnull()) & \n",
    "                                                                    (submissions_with_top_10_comments['comment_0'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert UTC timestamps to datetime\n",
    "\n",
    "submissions_with_top_10_comments['created_utc'] = pd.to_datetime(submissions_with_top_10_comments['created_utc'], unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename timestamp and top comment columns for improved clarity\n",
    "\n",
    "submissions_with_top_10_comments = submissions_with_top_10_comments.rename(columns={'created_utc': 'submission_date',\n",
    "                                                                                    'comment_0': 'top_comment_1',\n",
    "                                                                                    'comment_1': 'top_comment_2',\n",
    "                                                                                    'comment_2': 'top_comment_3',\n",
    "                                                                                    'comment_3': 'top_comment_4',\n",
    "                                                                                    'comment_4': 'top_comment_5',\n",
    "                                                                                    'comment_5': 'top_comment_6',\n",
    "                                                                                    'comment_6': 'top_comment_7',\n",
    "                                                                                    'comment_7': 'top_comment_8',\n",
    "                                                                                    'comment_8': 'top_comment_9',\n",
    "                                                                                    'comment_9': 'top_comment_10'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove submission_id column since it isn't important to the dataset\n",
    "\n",
    "submissions_with_top_10_comments = submissions_with_top_10_comments.drop('submission_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap decision and submission_title columns\n",
    "\n",
    "submissions_with_top_10_comments[['decision', 'submission_title']] = submissions_with_top_10_comments[['submission_title', 'decision']]\n",
    "submissions_with_top_10_comments = submissions_with_top_10_comments.rename(columns={'decision': 'submission_title', 'submission_title': 'decision'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap submission_score and submission_text columns\n",
    "\n",
    "submissions_with_top_10_comments[['submission_score', 'submission_text']] = submissions_with_top_10_comments[['submission_text', 'submission_score']]\n",
    "submissions_with_top_10_comments = submissions_with_top_10_comments.rename(columns={'submission_score': 'submission_text', 'submission_text': 'submission_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_with_top_10_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to output CSV and ZST\n",
    "- Will be considered as the \"raw\" version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a csv\n",
    "output_file = '2019_to_2022_submissions_at_least_50_score_top_10_comments.csv'\n",
    "submissions_with_top_10_comments.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress CSV file to ZST format and save it\n",
    "\n",
    "input_file = '2019_to_2022_submissions_at_least_50_score_top_10_comments.csv'\n",
    "output_file = '2019_to_2022_submissions_at_least_50_score_top_10_comments.zst'\n",
    "\n",
    "with open(input_file, 'rb') as f_in, open(output_file, 'wb') as f_out:\n",
    "    cctx = zstd.ZstdCompressor() # Create a zstd compressor\n",
    "    cctx.copy_stream(f_in, f_out) # Compress the input file and write the compressed data to the output file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
