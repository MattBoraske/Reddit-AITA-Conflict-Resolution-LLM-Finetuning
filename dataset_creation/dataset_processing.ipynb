{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AITA dataset processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets transformers pandas numpy seaborn krippendorff huggingface_hub ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:\\Users\\mattb\\Documents\\Github\\Reddit_AITA_Finetuning\\dataset_creation\n",
    "!mkdir processing_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "initial_datafile = '2019_to_2022_submissions_at_least_50_score_top_10_comments.csv'  # change to data file path\n",
    "dataset = Dataset.from_pandas(pd.read_csv(initial_datafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing of samples where top comment doesn't begin with AITA classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# regex pattern that matches rows where 'top_comment_1' starts with 'nta', 'yta', 'esh', 'info', or 'nah'\n",
    "regex = re.compile(r'^(nta|yta|esh|info|nah)', re.IGNORECASE)\n",
    "\n",
    "# function to apply the regex filter\n",
    "def filter_rows(example):\n",
    "    return bool(regex.match(example['top_comment_1']))\n",
    "\n",
    "# filter the dataset using the regex pattern\n",
    "filtered_dataset = dataset.filter(filter_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save AITA classification prefix filtering results\n",
    "\n",
    "rows_removed = dataset.num_rows - filtered_dataset.num_rows\n",
    "percent_change = (filtered_dataset.num_rows - dataset.num_rows) / dataset.num_rows * 100\n",
    "\n",
    "AITA_class_prefix_filtering_results = {\n",
    "    \"number of samples before filtering\": dataset.num_rows,\n",
    "    \"number of samples after filtering\": filtered_dataset.num_rows,\n",
    "    \"number of samples removed\": rows_removed,\n",
    "    \"percent change in number of samples\": percent_change,\n",
    "}\n",
    "\n",
    "output_file = \"processing_results/AITA_prefix_filtering_results.json\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(AITA_class_prefix_filtering_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Edits in both Submission Texts and Top Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_edits(text):\n",
    "  \"\"\"\n",
    "  Removes the edits portion of a text\n",
    "\n",
    "  Parameters:\n",
    "    text: A string containing the text.\n",
    "\n",
    "  Returns:\n",
    "    A string with the edits removed, if present.\n",
    "  \"\"\"\n",
    "\n",
    "  global edits_removed_counter\n",
    "\n",
    "  if text == None:\n",
    "    return text\n",
    "\n",
    "  text = text.lower()\n",
    "\n",
    "  pattern = r\"(edit:|edit -|edit-|eta:|eta -|eta-|edited:|edited -|edited-|edit after:|edit after- |edit after -|edit afterwards:|edit afterwards -|edit afterwards-|edited to add:|edited to add -|edited to add-|update:|update-|update -|updated:|updated-|updated -)\"\n",
    "  match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "  if match:\n",
    "      edits_removed_counter += 1 # increment the edits_removed_counter\n",
    "      return text[:match.start()].strip() # return the text up to the start of the match\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_length(strings):\n",
    "  \"\"\"\n",
    "  Calculates the average length of a list of strings.\n",
    "\n",
    "  Args:\n",
    "    strings (list): A list of strings.\n",
    "\n",
    "  Returns:\n",
    "    float: The average length of the strings.\n",
    "  \"\"\"\n",
    "\n",
    "  filtered_strings = [s for s in strings if s is not None] # filter out None values\n",
    "  total_length = sum(len(s) for s in filtered_strings)\n",
    "  average_length = total_length / len(filtered_strings) if filtered_strings else 0\n",
    "  return average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# create the results dictionary\n",
    "\n",
    "edits_removal_results = {\n",
    "    'submission_texts': defaultdict(list),\n",
    "    'top_comment_1': defaultdict(list),\n",
    "    'top_comment_2': defaultdict(list),\n",
    "    'top_comment_3': defaultdict(list),\n",
    "    'top_comment_4': defaultdict(list),\n",
    "    'top_comment_5': defaultdict(list),\n",
    "    'top_comment_6': defaultdict(list),\n",
    "    'top_comment_7': defaultdict(list),\n",
    "    'top_comment_8': defaultdict(list),\n",
    "    'top_comment_9': defaultdict(list),\n",
    "    'top_comment_10': defaultdict(list),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average lengths to result dictionary before removing edits\n",
    "\n",
    "texts_with_potential_edits = {\n",
    "    'submission_texts': dataset[\"submission_text\"],\n",
    "    'top_comment_1': dataset[\"top_comment_1\"],\n",
    "    'top_comment_2': dataset[\"top_comment_2\"],\n",
    "    'top_comment_3': dataset[\"top_comment_3\"],\n",
    "    'top_comment_4': dataset[\"top_comment_4\"],\n",
    "    'top_comment_5': dataset[\"top_comment_5\"],\n",
    "    'top_comment_6': dataset[\"top_comment_6\"],\n",
    "    'top_comment_7': dataset[\"top_comment_7\"],\n",
    "    'top_comment_8': dataset[\"top_comment_8\"],\n",
    "    'top_comment_9': dataset[\"top_comment_9\"],\n",
    "    'top_comment_10': dataset[\"top_comment_10\"],\n",
    "}\n",
    "\n",
    "for key, texts in texts_with_potential_edits.items():\n",
    "    edits_removal_results[key]['avg_length_before_removing_edits'] = get_avg_length(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove edits for submissions and comments\n",
    "\n",
    "edits_removed_counter = 0\n",
    "\n",
    "# submission texts\n",
    "dataset = dataset.map(lambda x: {\"submission_text\": remove_edits(x[\"submission_text\"])})\n",
    "edits_removal_results['submission_texts']['edits_removed'] = edits_removed_counter\n",
    "\n",
    "# comments\n",
    "for i in range(1, 11):\n",
    "    edits_removed_counter = 0\n",
    "    dataset = dataset.map(lambda x: {f\"top_comment_{i}\": remove_edits(x[f\"top_comment_{i}\"])})\n",
    "    edits_removal_results[f\"top_comment_{i}\"]['edits_removed'] = edits_removed_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add string lengths to result dictionary after removing edits\n",
    "\n",
    "texts_with_potential_edits = {\n",
    "    'submission_texts': dataset[\"submission_text\"],\n",
    "    'top_comment_1': dataset[\"top_comment_1\"],\n",
    "    'top_comment_2': dataset[\"top_comment_2\"],\n",
    "    'top_comment_3': dataset[\"top_comment_3\"],\n",
    "    'top_comment_4': dataset[\"top_comment_4\"],\n",
    "    'top_comment_5': dataset[\"top_comment_5\"],\n",
    "    'top_comment_6': dataset[\"top_comment_6\"],\n",
    "    'top_comment_7': dataset[\"top_comment_7\"],\n",
    "    'top_comment_8': dataset[\"top_comment_8\"],\n",
    "    'top_comment_9': dataset[\"top_comment_9\"],\n",
    "    'top_comment_10': dataset[\"top_comment_10\"],\n",
    "}\n",
    "\n",
    "for key, texts in texts_with_potential_edits.items():\n",
    "    edits_removal_results[key]['avg_length_after_removing_edits'] = get_avg_length(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add percent changes in average lengths from removing edits\n",
    "\n",
    "def calculate_percent_change(before, after):\n",
    "    if before == 0:\n",
    "        return 0\n",
    "    return ((after - before) / before) * 100\n",
    "\n",
    "for key in edits_removal_results.keys():\n",
    "    before = edits_removal_results[key]['avg_length_before_removing_edits']\n",
    "    after = edits_removal_results[key]['avg_length_after_removing_edits']\n",
    "    percent_change = calculate_percent_change(before, after)\n",
    "    edits_removal_results[key]['avg_length_percent_change'] = percent_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save edits removal results\n",
    "\n",
    "output_file = \"processing_results/edits_removal_results.json\"\n",
    "\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(edits_removal_results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Upper Extreme Outliers\n",
    "Two-step filtering process:\n",
    "1. Removal of Samples with submissions that are top 2% of length\n",
    "2. Removal of Samples with #1 comments that are top 2% in length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_submission_length(sample):\n",
    "    return {'submission_text_length': len(sample['submission_text'])}\n",
    "\n",
    "def calculate_comment_length(sample):\n",
    "    return {'top_comment_1_length': len(sample['top_comment_1'])}\n",
    "\n",
    "def filter_submission_upper_outliers(example):\n",
    "    return example['submission_text_length'] <= submission_text_length_threshold\n",
    "\n",
    "def filter_comment_upper_outliers(example):\n",
    "    return example['top_comment_1_length'] <= top_comment_length_threshold\n",
    "\n",
    "# Apply the functions to the dataset\n",
    "dataset = dataset.map(calculate_submission_length)\n",
    "dataset = dataset.map(calculate_comment_length)\n",
    "\n",
    "# Extract lengths into lists\n",
    "submission_text_lengths = dataset['submission_text_length']  # Adjust split if needed\n",
    "top_comment_lengths = dataset['top_comment_1_length']        # Adjust split if needed\n",
    "\n",
    "# Calculate the 98th percentile thresholds\n",
    "submission_text_length_threshold = np.percentile(submission_text_lengths, 98)\n",
    "top_comment_length_threshold = np.percentile(top_comment_lengths, 98)\n",
    "\n",
    "# Filter the dataset\n",
    "rows_before = dataset.num_rows\n",
    "dataset = dataset.filter(filter_submission_upper_outliers)\n",
    "dataset = dataset.filter(filter_comment_upper_outliers)\n",
    "rows_after = dataset.num_rows\n",
    "\n",
    "percent_change = (rows_after - rows_before) / rows_before * 100\n",
    "\n",
    "# Save outlier filtering results\n",
    "outlier_filtering_results ={\n",
    "    \"number of samples before filtering\": rows_before,\n",
    "    \"number of samples after filtering\": rows_after,\n",
    "    \"number of samples removed\": rows_before - rows_after,\n",
    "    \"percent change in number of samples\": percent_change,\n",
    "}\n",
    "\n",
    "output_file = \"processing_results/outlier_filtering_results.json\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(outlier_filtering_results, f)\n",
    "\n",
    "# Remove the length columns\n",
    "dataset = dataset.remove_columns(['submission_text_length', 'top_comment_1_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding of Comment AITA Classifications And Ambiguity Scores for Each Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def find_earliest_classification(text):\n",
    "    '''\n",
    "    Find the earliest AITA classification in a text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to search for AITA classifications in.\n",
    "\n",
    "    Returns:\n",
    "        str: The earliest classification found in the text.\n",
    "    '''\n",
    "\n",
    "    # classifications mapped to their keywords\n",
    "    classes_dictionary = {\n",
    "      'NTA': ['not the asshole', 'not the a\\*\\*hole', 'nta', 'you would not be the asshole', 'you would not be the a**hole', 'ywnbta', 'n t a', 'y w b t a'],\n",
    "      'NAH': ['no assholes here', 'no a\\*\\*holes here', 'nah', 'n a h'],\n",
    "      'ESH': ['everyone sucks here', 'esh', 'e s h'],\n",
    "      'INFO': ['more information needed', 'more info needed', 'more information required', 'more info required', 'info'],\n",
    "      'YTA': ['you\\'re the asshole', 'you\\'re the a\\*\\*hole', 'youre the asshole', 'youre the a\\*\\*hole', 'yta', 'you would be the asshole', 'you would be the a\\*\\*hole', 'ywbta', 'y t a', 'y w b t a']\n",
    "    }\n",
    "\n",
    "    # track earliest match\n",
    "    earliest_match = None\n",
    "    earliest_match_pos = float('inf')  # Initially set to infinity\n",
    "\n",
    "    # convert input text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # go through all classifications and their keywords\n",
    "    for key, phrases in classes_dictionary.items():\n",
    "        # Create a regex pattern that includes the classification keywords\n",
    "        pattern = r'\\b(' + '|'.join(map(re.escape, phrases)) + r')\\b'\n",
    "\n",
    "        # Search for any keywords in the input text\n",
    "        for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "            if match.start() < earliest_match_pos:\n",
    "                # Update the earliest match if this match is earlier\n",
    "                earliest_match = key\n",
    "                earliest_match_pos = match.start()\n",
    "\n",
    "    # return the class that had the earliest match\n",
    "    return earliest_match\n",
    "\n",
    "def add_classification(row):\n",
    "    '''\n",
    "    Add comment AITA classifications to a row in the datset.\n",
    "\n",
    "    Args:\n",
    "        row (dict): A row from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: The row with comment AITA classifications added.\n",
    "    '''\n",
    "    # Iterate over top 10 comment keys\n",
    "    for i in range(1, 11):\n",
    "        key = f'top_comment_{i}'\n",
    "        if key in row and isinstance(row[key], str):\n",
    "            # if this row has a top_comment_N key, get the classification and add it to the row\n",
    "            classification = find_earliest_classification(row[key])\n",
    "            row[key + '_classification'] = classification\n",
    "        else:\n",
    "            # If the top_comment_N key doesn't exist, skip setting this key\n",
    "            row[key + '_classification'] = None\n",
    "\n",
    "    # return the row with the classification added\n",
    "    return row\n",
    "\n",
    "def calculate_ambiguity(classifications):\n",
    "    '''\n",
    "    Calculate the ambiguity score for a list of classifications.\n",
    "\n",
    "    Args:\n",
    "        classifications (list): A list of classifications.\n",
    "\n",
    "    Returns:\n",
    "        float: The ambiguity score.\n",
    "    '''\n",
    "    classification_values = {'YTA': 1, 'ESH': 2,\n",
    "                             'INFO': 3, 'NAH': 4,\n",
    "                             'NTA': 5}\n",
    "\n",
    "    # convert classifications to their numeric representations\n",
    "    numeric_values = [classification_values[c] for c in classifications if c is not None]\n",
    "\n",
    "    # calculate ambiguity score as a function of mean and std dev\n",
    "    mean = np.mean(numeric_values)\n",
    "    std_dev = np.std(numeric_values)\n",
    "    def f(mean):\n",
    "        return (2 - abs(3 - mean)) ** 2 # parabolic that is lowest when mean is 1 or 5 and highest at 3 to emphasize ambiguity for YTA & NTA classes\n",
    "    ambiguity_score = std_dev * f(mean)\n",
    "\n",
    "    # normalize the ambiguity score on a 0-1 scale\n",
    "    min_score = 0  # Minimum possible score (when std dev equals 0)\n",
    "    max_score = 8.0  # Maximum possible score (when classes are equally YTA and NTA which results in max std dev and a central mean)\n",
    "    normalized_score = (ambiguity_score - min_score) / (max_score - min_score)\n",
    "\n",
    "    # return normalized ambiguity score\n",
    "    return normalized_score\n",
    "\n",
    "def add_ambiguity_score(row):\n",
    "    # extract classifications from top comments\n",
    "    classifications = []\n",
    "    for i in range(1, 11):  # Adjust the range based on the number of top comments\n",
    "        classification_key = f'top_comment_{i}_classification'\n",
    "        if classification_key in row and row[classification_key]:\n",
    "            classifications.append(row[classification_key])\n",
    "\n",
    "    # calculate the ambiguity score if there are classifications\n",
    "    if classifications:\n",
    "        row['ambiguity_score'] = calculate_ambiguity(classifications)\n",
    "    else:\n",
    "        row['ambiguity_score'] = None\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add top comment classifications to dataset\n",
    "dataset = dataset.map(add_classification)\n",
    "\n",
    "# convert dataset to dataframe for null filtering\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# remove the rows where the top 1 comment classification is None\n",
    "rows_before = df.shape[0]\n",
    "df_filtered = df[df['top_comment_1_classification'].notnull()]\n",
    "rows_after = df_filtered.shape[0]\n",
    "rows_removed = rows_before - rows_after\n",
    "percent_change = (rows_removed / rows_before) * 100\n",
    "\n",
    "# save results of filtering out rows with null top comment classifications\n",
    "top_comment_classification_null_filtering_results = {\n",
    "    \"number of samples before filtering\": rows_before,\n",
    "    \"number of samples after filtering\": rows_after,\n",
    "    \"number of samples removed\": rows_removed,\n",
    "    \"percent change in number of samples\": percent_change,\n",
    "}\n",
    "\n",
    "output_file = \"processing_results/top_comment_classification_null_filtering_results.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(top_comment_classification_null_filtering_results, f)\n",
    "\n",
    "# convert dataframe back to a dataset\n",
    "dataset = Dataset.from_pandas(df_filtered)\n",
    "\n",
    "# add ambiguity scores to dataset\n",
    "dataset = dataset.map(add_ambiguity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before_class_labels = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before_class_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_before_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before_class_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda example: {'AITA_decision': example['decision']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "\n",
    "# Create a mapping for the unique decision strings to integer labels\n",
    "unique_labels = sorted(set(dataset['decision']))\n",
    "label_to_id = {label: id for id, label in enumerate(unique_labels)}\n",
    "\n",
    "# Define a function to map each decision to its integer label\n",
    "def add_decision_class_label(example):\n",
    "    example['decision_class_label'] = label_to_id[example['decision']]\n",
    "    return example\n",
    "\n",
    "# Add the 'decision_class_label' column to the dataset\n",
    "dataset = dataset.map(add_decision_class_label)\n",
    "\n",
    "# Update the features of the dataset to include 'decision_class_label'\n",
    "new_features = dataset.features.copy()\n",
    "new_features['decision_class_label'] = ClassLabel(names=unique_labels)\n",
    "dataset = dataset.cast(new_features)\n",
    "\n",
    "# Remove the original 'decision' column\n",
    "dataset = dataset.remove_columns('decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_aita_decision(sample):\n",
    "    # Check if 'AITA_decision' is 'Asshole' and update it\n",
    "    if sample['AITA_decision'] == 'Asshole':\n",
    "        sample['AITA_decision'] = 'A-hole'\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(update_aita_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(\n",
    "    test_size = 0.2,\n",
    "    stratify_by_column='decision_class_label',\n",
    "    seed=42 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding of Flan-T5 and Llama-2 Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AITA_instruction import AITA_Instruction\n",
    "\n",
    "# adding of Flan-T5 instructions\n",
    "dataset[\"train\"] = dataset[\"train\"].map(AITA_Instruction.get_flanT5_instruction, batched=False)\n",
    "dataset[\"test\"] = dataset[\"test\"].map(AITA_Instruction.get_flanT5_instruction, batched=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding of Llama2 instructions\n",
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    lambda sample: AITA_Instruction.get_llama2_training_instruction(sample, instruction_type=\"training\"), \n",
    "    batched=False\n",
    ")\n",
    "\n",
    "dataset[\"test\"] = dataset[\"test\"].map(\n",
    "    lambda sample: AITA_Instruction.get_llama2_training_instruction(sample, instruction_type=\"testing\"), \n",
    "    batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving of Main Dataset to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_USERNAME = \"MattBoraske\" # Change to your Hugging Face username\n",
    "dataset.push_to_hub(f'{HF_USERNAME}/reddit-AITA-submissions-and-comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of \"High-Quality\" Dataset\n",
    "- \"Top 2500\"\n",
    "    - Top 400 training samples and top 100 testing samples of each AITA class by submission_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('MattBoraske/reddit-AITA-submissions-and-comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def filter_top_samples_df(dataset, top_n):\n",
    "    # Convert to Pandas DataFrame\n",
    "    df = dataset.to_pandas()\n",
    "\n",
    "    # Drop the '__index_level_0__' column if it exists\n",
    "    if '__index_level_0__' in df.columns:\n",
    "        df = df.drop(columns=['__index_level_0__'])\n",
    "\n",
    "    # Group by 'decision_class_label', sort within groups by 'submission_score', and take top N\n",
    "    grouped = df.groupby('decision_class_label', group_keys=False).apply(lambda x: x.nlargest(top_n, 'submission_score'))\n",
    "    return Dataset.from_pandas(grouped)\n",
    "\n",
    "# Filter the datasets and convert to DataFrames\n",
    "filtered_train_df = filter_top_samples_df(dataset['train'], 400)\n",
    "filtered_test_df = filter_top_samples_df(dataset['test'], 100)\n",
    "\n",
    "# Create a new DatasetDict\n",
    "samples_2500_dataset = DatasetDict({\n",
    "    'train': filtered_train_df,\n",
    "    'test': filtered_test_df\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_2500_dataset.push_to_hub(f'{HF_USERNAME}/reddit-AITA-submissions-and-comments-top-2500')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
